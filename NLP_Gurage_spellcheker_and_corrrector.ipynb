{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aronsinkie/NIDS/blob/master/NLP_Gurage_spellcheker_and_corrrector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rena-I0opc-o"
      },
      "source": [
        "#Mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AXcvTamb0Cs",
        "outputId": "47b5a4d4-fd52-4775-d273-0b8e9c319103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlegbBLS_49L"
      },
      "source": [
        "# ትግበራዎች"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiiCJY2UArgH"
      },
      "source": [
        "## ጥቅል"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMVukaJBi9Of",
        "outputId": "5d53cfde-47c9-4f41-c7e8-0c9654295756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "pip install colorama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBi2opVBqJu9"
      },
      "source": [
        "# ቅጥያን ማስዎገድ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4nFsnovkUwp"
      },
      "outputs": [],
      "source": [
        "def remove_amharic_noun_affixes(word):\n",
        "    for prefix in amharic_noun_prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            word = word[len(prefix):]\n",
        "            break\n",
        "    for suffix in amharic_noun_suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            word = word[:-len(suffix)]\n",
        "            break\n",
        "    return word#.rstrip(word[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed98eKBsndE3"
      },
      "outputs": [],
      "source": [
        "def remove_amharic_verb_affixes(word):\n",
        "    for prefix in amharic_verb_prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            word = word[len(prefix):]\n",
        "            break\n",
        "    for suffix in amharic_verb_suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            word = word[:-len(suffix)]\n",
        "            break\n",
        "    return word#.rstrip(word[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNUPR2YWyN5m"
      },
      "outputs": [],
      "source": [
        "def remove_amharic_adj_affixes(word):\n",
        "    for prefix in amharic_adj_prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            word = word[len(prefix):]\n",
        "            break\n",
        "    for suffix in amharic_adj_suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            word = word[:-len(suffix)]\n",
        "            break\n",
        "    return word#.rstrip(word[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbGztI1ipzeY"
      },
      "source": [
        "# ተነባቢ ዐናባቢ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGtXiPr6jray"
      },
      "outputs": [],
      "source": [
        "RIBI = {\n",
        "'ሐ':'ሕአ',\n",
        "'ሑ':'ሕኡ',\n",
        "'ሒ':'ሕኢ',\n",
        "'ሓ':'ሕኣ',\n",
        "'ሔ':'ሕኤ',\n",
        "'ሕ':'ሕ',\n",
        "'ሖ':'ሕኦ',\n",
        "'𞟨':'𞟫አ',\n",
        "'ሑ':'ሕኡ',\n",
        "'𞟩':'𞟫ኢ',\n",
        "'ሗ':'𞟫ኣ',\n",
        "'𞟪':'𞟫ኤ',\n",
        "'𞟫':'𞟫',\n",
        "'ሖ':'ሕኦ',\n",
        "'𞟠':'𞟥አ',\n",
        "'𞟡':'𞟥ኡ',\n",
        "'𞟢':'𞟥ኢ',\n",
        "'𞟣':'𞟥ኣ',\n",
        "'𞟤':'𞟥ኤ',\n",
        "'𞟥':'𞟥',\n",
        "'𞟦':'𞟥ኦ',\n",
        "'ለ':'ልአ',\n",
        "'ሉ':'ልኡ',\n",
        "'ሊ':'ልኢ',\n",
        "'ላ':'ልኣ',\n",
        "'ሌ':'ልኤ',\n",
        "'ል':'ል',\n",
        "'ሎ':'ልኦ',\n",
        "'መ':'ምአ',\n",
        "'ሙ':'ምኡ',\n",
        "'ሚ':'ምኢ',\n",
        "'ማ':'ምኣ',\n",
        "'ሜ':'ምኤ',\n",
        "'ም':'ም',\n",
        "'ሞ':'ምኦ',\n",
        "'ᎀ':'ᎃአ',\n",
        "'ሙ':'ምኡ',\n",
        "'𞟭':'ᎃኢ',\n",
        "'ሟ':'ᎃኣ',\n",
        "'𞟮':'ᎃኤ',\n",
        "'ᎃ':'ᎃ',\n",
        "'ሞ':'ምኦ',\n",
        "'ረ':'ርአ',\n",
        "'ሩ':'ርኡ',\n",
        "'ሪ':'ርኢ',\n",
        "'ራ':'ርኣ',\n",
        "'ሬ':'ርኤ',\n",
        "'ር':'ር',\n",
        "'ሮ':'ርኦ',\n",
        "'ሰ':'ስአ',\n",
        "'ሱ':'ስኡ',\n",
        "'ሲ':'ስኢ',\n",
        "'ሳ':'ስኣ',\n",
        "'ሴ':'ስኤ',\n",
        "'ስ':'ስ',\n",
        "'ሶ':'ስኦ',\n",
        "'ሸ':'ሽአ',\n",
        "'ሹ':'ሽኡ',\n",
        "'ሺ':'ሽኢ',\n",
        "'ሻ':'ሽኣ',\n",
        "'ሼ':'ሽኤ',\n",
        "'ሽ':'ሽ',\n",
        "'ሾ':'ሽኦ',\n",
        "'ቀ':'ቅአ',\n",
        "'ቁ':'ቅኡ',\n",
        "'ቂ':'ቅኢ',\n",
        "'ቃ':'ቅኣ',\n",
        "'ቄ':'ቅኤ',\n",
        "'ቅ':'ቅ',\n",
        "'ቆ':'ቅኦ',\n",
        "'ቈ':'ቅአ',\n",
        "'ቁ':'ቅኡ',\n",
        "'𞟰':'𞟲ኢ',\n",
        "'ቋ':'𞟲ኣ',\n",
        "'𞟱':'𞟲ኤ',\n",
        "'𞟲':'𞟲',\n",
        "'ቆ':'ቅኦ',\n",
        "'ቐ':'ቕአ',\n",
        "'ቑ':'ቕኡ',\n",
        "'ቒ':'ቕኢ',\n",
        "'ቓ':'ቕኣ',\n",
        "'ቔ':'ቕኤ',\n",
        "'ቕ':'ቕ',\n",
        "'ቖ':'ቕኦ',\n",
        "'በ':'ብአ',\n",
        "'ቡ':'ብኡ',\n",
        "'ቢ':'ብኢ',\n",
        "'ባ':'ብኣ',\n",
        "'ቤ':'ብኤ',\n",
        "'ብ':'ብ',\n",
        "'ቦ':'ብኦ',\n",
        "'ᎄ':'ᎇአ',\n",
        "'ቡ':'ብኡ',\n",
        "'𞟳':'𞟳ኢ',\n",
        "'ቧ':'ᎇኣ',\n",
        "'𞟴':'ᎇኤ',\n",
        "'ᎇ':'ᎇ',\n",
        "'ቦ':'ብኦ',\n",
        "'ተ':'ትአ',\n",
        "'ቱ':'ትኡ',\n",
        "'ቲ':'ትኢ',\n",
        "'ታ':'ትኣ',\n",
        "'ቴ':'ትኤ',\n",
        "'ት':'ት',\n",
        "'ቶ':'ትኦ',\n",
        "'ቸ':'ችአ',\n",
        "'ቹ':'ችኡ',\n",
        "'ቺ':'ችኢ',\n",
        "'ቻ':'ችኣ',\n",
        "'ቼ':'ችኤ',\n",
        "'ች':'ች',\n",
        "'ቾ':'ችኦ',\n",
        "'ነ':'ንአ',\n",
        "'ኑ':'ንኡ',\n",
        "'ኒ':'ንኢ',\n",
        "'ና':'ንኣ',\n",
        "'ኔ':'ንኤ',\n",
        "'ን':'ን',\n",
        "'ኖ':'ንኦ',\n",
        "'ኘ':'ኝአ',\n",
        "'ኙ':'ኝኡ',\n",
        "'ኚ':'ኝኢ',\n",
        "'ኛ':'ኝኣ',\n",
        "'ኜ':'ኝኤ',\n",
        "'ኝ':'ኝ',\n",
        "'ኞ':'ኝኦ',\n",
        "'አ':'አ',\n",
        "'ኡ':'ኡ',\n",
        "'ኢ':'ኢ',\n",
        "'ኣ':'ኣ',\n",
        "'ኤ':'ኤ',\n",
        "'እ':'እ',\n",
        "'ኦ':'ኦ',\n",
        "'ከ':'ክአ',\n",
        "'ኩ':'ክኡ',\n",
        "'ኪ':'ክኢ',\n",
        "'ካ':'ክኣ',\n",
        "'ኬ':'ክኤ',\n",
        "'ክ':'ክእ',\n",
        "'ኮ':'ክኦ',\n",
        "'ኰ':'𞟷አ',\n",
        "'ኩ':'ክኡ',\n",
        "'𞟵':'𞟷ኢ',\n",
        "'ኳ':'𞟷ኣ',\n",
        "'𞟶':'𞟷ኤ',\n",
        "'𞟷':'𞟷',\n",
        "'ኮ':'ክኦ',\n",
        "'ኸ':'ኽአ',\n",
        "'ኹ':'ኽኡ',\n",
        "'ኺ':'ኽኢ',\n",
        "'ኻ':'ኽኣ',\n",
        "'ኼ':'ኽኤ',\n",
        "'ኽ':'ኽ',\n",
        "'ኾ':'ኽኦ',\n",
        "'ወ':'ውአ',\n",
        "'ዉ':'ውኡ',\n",
        "'ዊ':'ውኢ',\n",
        "'ዋ':'ውኣ',\n",
        "'ዌ':'ውኤ',\n",
        "'ው':'ው',\n",
        "'ዎ':'ውኦ',\n",
        "'ዐ':'ዕአ',\n",
        "'ዑ':'ዕኡ',\n",
        "'ዒ':'ዕኢ',\n",
        "'ዓ':'ዕኣ',\n",
        "'ዔ':'ዕኤ',\n",
        "'ዕ':'ዕ',\n",
        "'ዖ':'ዕኦ',\n",
        "'ዘ':'ዝአ',\n",
        "'ዙ':'ዝኡ',\n",
        "'ዚ':'ዝኢ',\n",
        "'ዛ':'ዝኣ',\n",
        "'ዜ':'ዝኤ',\n",
        "'ዝ':'ዝ',\n",
        "'ዞ':'ዝኦ',\n",
        "'ዠ':'ዥአ',\n",
        "'ዡ':'ዥኡ',\n",
        "'ዢ':'ዥኢ',\n",
        "'ዣ':'ዥኣ',\n",
        "'ዤ':'ዥኤ',\n",
        "'ዥ':'ዥእ',\n",
        "'ዦ':'ዥኦ',\n",
        "'የ':'ይአ',\n",
        "'ዩ':'ዩኡ',\n",
        "'ዪ':'ይኢ',\n",
        "'ያ':'ይኣ',\n",
        "'ዬ':'ይኤ',\n",
        "'ይ':'ይ',\n",
        "'ዮ':'ይኦ',\n",
        "'ደ':'ድአ',\n",
        "'ዱ':'ድኡ',\n",
        "'ዲ':'ድኢ',\n",
        "'ዳ':'ድኣ',\n",
        "'ዴ':'ድኤ',\n",
        "'ድ':'ድ',\n",
        "'ዶ':'ድኦ',\n",
        "'ጀ':'ጅአ',\n",
        "'ጁ':'ጅኡ',\n",
        "'ጂ':'ጅኢ',\n",
        "'ጃ':'ጅኣ',\n",
        "'ጄ':'ጅኤ',\n",
        "'ጅ':'ጅ',\n",
        "'ጂ':'ጅኦ',\n",
        "'ገ':'ግአ',\n",
        "'ጉ':'ግኡ',\n",
        "'ጊ':'ግኢ',\n",
        "'ጋ':'ግኣ',\n",
        "'ጌ':'ግኤ',\n",
        "'ግ':'ግእ',\n",
        "'ጎ':'ግኦ',\n",
        "'ጐ':'ግአ',\n",
        "'ጉ':'ግኡ',\n",
        "'𞟸':'𞟺ኢ',\n",
        "'ጓ':'𞟺ኣ',\n",
        "'𞟹':'𞟺ኤ',\n",
        "'𞟺':'𞟺',\n",
        "'ጎ':'ገኦ',\n",
        "'ጘ':'ጝአ',\n",
        "'ጙ':'ጝኡ',\n",
        "'ጚ':'ጝኢ',\n",
        "'ጛ':'ጝኣ',\n",
        "'ጜ':'ጝኤ',\n",
        "'ጝ':'ጝ',\n",
        "'ጞ':'ጝኦ',\n",
        "'ጠ':'ጥአ',\n",
        "'ጡ':'ጥኡ',\n",
        "'ጢ':'ጥኢ',\n",
        "'ጣ':'ጥኣ',\n",
        "'ጤ':'ጥኤ',\n",
        "'ጥ':'ጥ',\n",
        "'ጦ':'ጥኦ',\n",
        "'ጨ':'ጭአ',\n",
        "'ጩ':'ጭኡ',\n",
        "'ጪ':'ጭኢ',\n",
        "'ጫ':'ጭኣ',\n",
        "'ጬ':'ጭኤ',\n",
        "'ጭ':'ጭእ',\n",
        "'ጮ':'ጭኦ',\n",
        "'ፈ':'ፍአ',\n",
        "'ፉ':'ፍኡ',\n",
        "'ፊ':'ፍኢ',\n",
        "'ፋ':'ፍኣ',\n",
        "'ፌ':'ፍኤ',\n",
        "'ፍ':'ፍ',\n",
        "'ፎ':'ፍኦ',\n",
        "'ᎈ':'ᎋአ',\n",
        "'ፉ':'ᎋኡ',\n",
        "'𞟻':'ᎋኢ',\n",
        "'ፏ':'ᎋኣ',\n",
        "'𞟼':'ᎋኤ',\n",
        "'ᎋ':'ᎋ',\n",
        "'ፎ':'ፍኦ',\n",
        "'ፐ':'ፕአ',\n",
        "'ፑ':'ፕኡ',\n",
        "'ፒ':'ፕኢ',\n",
        "'ፓ':'ፕኣ',\n",
        "'ፔ':'ፕኤ',\n",
        "'ፕ':'ፕእ',\n",
        "'ፖ':'ፕኦ',\n",
        "'ᎌ':'ᎏአ',\n",
        "'ፑ':'ፕኡ',\n",
        "'𞟽':'ᎏኢ',\n",
        "'𞟾':'ᎏኤ',\n",
        "'ᎏ':'ᎏ',\n",
        "'ፓ':'ፕኦ',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bRO151zkz3g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzu-T7zIvmW0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GATlxdAmqXGE"
      },
      "source": [
        "# ዋና ቃል ምስረታ(so_called_steam_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDdcWgdQlP3k"
      },
      "outputs": [],
      "source": [
        "def so_called_steam_noun_word(word):\n",
        "    for prefix in amharic_noun_prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            word = word[len(prefix):]\n",
        "            break\n",
        "    for suffix in amharic_noun_suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            word = word[:-len(suffix)]\n",
        "            break\n",
        "        word = word.replace(\"-\", \"\")\n",
        "    return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JsTWrGmhww3"
      },
      "outputs": [],
      "source": [
        "def so_called_steam_verb_word(word):\n",
        "    for prefix in amharic_verb_prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            word = word[len(prefix):]\n",
        "            break\n",
        "    for suffix in amharic_verb_suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            word = word[:-len(suffix)]\n",
        "            break\n",
        "        word = word.replace(\"-\", \"\")\n",
        "    return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upWMESWMhdDN"
      },
      "outputs": [],
      "source": [
        "def so_called_steam_adj_word(word):\n",
        "    for prefix in amharic_adj_prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            word = word[len(prefix):]\n",
        "            break\n",
        "    for suffix in amharic_adj_suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            word = word[:-len(suffix)]\n",
        "            break\n",
        "        word = word.replace(\"-\", \"\")\n",
        "    return word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt7lGInCqlmp"
      },
      "source": [
        "# ተነባቢ አናባቢ ትንትና ትግበራ(Erbata_TIGBERA and reverse_Erbata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAAJeoS4lb7R"
      },
      "outputs": [],
      "source": [
        "def Erbata_TIGBERA(KAL: str, RIBI: dict) -> str:\n",
        "    Anababi_Erbata = [RIBI.get(FIDEL, '') for FIDEL in KAL]\n",
        "    Anababi_Erbata = '-'.join(Anababi_Erbata)\n",
        "    return Anababi_Erbata\n",
        "def reverse_Erbata(KAL: str, RIBI: dict) -> str:\n",
        "    split_words = KAL.split(\"-\")\n",
        "    new_word = ''\n",
        "    for split_word in split_words:\n",
        "        for key, value in RIBI.items():\n",
        "            if value == split_word:\n",
        "                new_word += key\n",
        "                break\n",
        "        else:\n",
        "            new_word += split_word\n",
        "        new_word += '-'\n",
        "    return new_word.rstrip('-')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdx5asePrdXz"
      },
      "source": [
        "# ቃላትን ማርባት"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3oXllXRlsRI"
      },
      "outputs": [],
      "source": [
        "def add_amharic_noun_affixes(stem_word):\n",
        "    words_with_affixes = []\n",
        "\n",
        "    for prefix in amharic_noun_prefixes:\n",
        "        words_with_affixes.append(prefix + stem_word)\n",
        "\n",
        "    for suffix in amharic_noun_suffixes:\n",
        "        words_with_affixes.append(stem_word[:-1] + suffix)\n",
        "\n",
        "    return words_with_affixes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdFL4WB2zaVI"
      },
      "outputs": [],
      "source": [
        "def add_amharic_verb_affixes(stem_word):\n",
        "    words_with_affixes = []\n",
        "\n",
        "    for prefix in amharic_verb_prefixes:\n",
        "        words_with_affixes.append(prefix + stem_word)\n",
        "\n",
        "    for suffix in amharic_verb_suffixes:\n",
        "        words_with_affixes.append(stem_word[:-1] + suffix)\n",
        "\n",
        "    return words_with_affixes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OATLjkvnzcbw"
      },
      "outputs": [],
      "source": [
        "def add_amharic_adj_affixes(stem_word):\n",
        "    words_with_affixes = []\n",
        "\n",
        "    for prefix in amharic_adj_prefixes:\n",
        "        words_with_affixes.append(prefix + stem_word)\n",
        "\n",
        "    for suffix in amharic_adj_suffixes:\n",
        "        words_with_affixes.append(stem_word[:-1] + suffix)\n",
        "\n",
        "    return words_with_affixes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPnH4Q0Rrtf-"
      },
      "source": [
        "# ሰረዝን ማጥፋት"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjyV9eGYl5PO"
      },
      "outputs": [],
      "source": [
        "def remove_hyphen(word):\n",
        "    return word.replace(\"-\", \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnBcNS3xrzSv"
      },
      "source": [
        "# ከዋና ቅል ከረጢት ጋር ማመሳሰል"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIjhunagpWlj"
      },
      "outputs": [],
      "source": [
        "def check_string_in_file(file_path, search_string):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            for line in file:\n",
        "                if search_string.encode('utf-8') in line.encode('utf-8'):\n",
        "                    return True\n",
        "        return False\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{file_path}' not found.\")\n",
        "        return False\n",
        "    except IOError:\n",
        "        print(f\"Error reading file '{file_path}'.\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDgSBKg1sQ4n"
      },
      "source": [
        "# ከዋና ቃል ቅርብ የሖነውን መፈለግ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilb0a-HPpfP3"
      },
      "outputs": [],
      "source": [
        "def find_closest_word(root_word, misspelled_word):\n",
        "    with open(root_word, \"r\", encoding=\"utf-8\") as file:\n",
        "        root_words = [line.strip() for line in file]\n",
        "\n",
        "    closest_word = difflib.get_close_matches(misspelled_word, root_words, n=1)\n",
        "    if closest_word:\n",
        "        return closest_word[0]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7ULOWofsjXI"
      },
      "source": [
        "# family and order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiK_9LDssUa3"
      },
      "outputs": [],
      "source": [
        "def family(char1, char2):\n",
        "    char1 = Erbata_TIGBERA(char1, RIBI)\n",
        "    char2 = Erbata_TIGBERA(char2, RIBI)\n",
        "    if len(char1) <  2 and len(char2)< 2:\n",
        "      return 1\n",
        "    elif char1[0] == char2[0]:\n",
        "        return 1\n",
        "    elif len(char1) < 1 or len(char2) < 1:\n",
        "      return 0\n",
        "    return 0\n",
        "def order(char1, char2):\n",
        "\n",
        "        char1 = Erbata_TIGBERA(char1, RIBI)\n",
        "        char2 = Erbata_TIGBERA(char2, RIBI)\n",
        "        if len(char1) >= 2 and len(char2) >= 2:\n",
        "          if char1[1] == char2[1]:\n",
        "            return 1\n",
        "        if len(char1) < 2 and len(char2) >= 2:\n",
        "          if char1[0] == char2[1]:\n",
        "            return 1\n",
        "        if len(char1) >=  2 and len(char2)< 2:\n",
        "          if char1[1] == char2[0]:\n",
        "            return 1\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf_j8vCgtJE9"
      },
      "source": [
        "# ተመሳሳይ ሖሒያትን መፈለግ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIbQvd_gsbnA"
      },
      "outputs": [],
      "source": [
        "def match_words(word1, word2):\n",
        "    matched_chars = \"\"\n",
        "    unmatched_chars1_before = \"\"\n",
        "    unmatched_chars1_after = \"\"\n",
        "    unmatched_chars2_before = \"\"\n",
        "    unmatched_chars2_after = \"\"\n",
        "\n",
        "    if word1 is None or word2 is None:\n",
        "        return matched_chars, unmatched_chars1_before, unmatched_chars1_after, unmatched_chars2_before, unmatched_chars2_after\n",
        "\n",
        "    # Convert the words into lists of characters\n",
        "    word1_list = list(word1)\n",
        "    word2_list = list(word2)\n",
        "\n",
        "    # Iterate over each character in word1\n",
        "    for char1 in word1_list:\n",
        "        # Iterate over each character in word2\n",
        "        for char2 in word2_list:\n",
        "            if char1 == char2:\n",
        "                matched_chars += char1\n",
        "\n",
        "    if matched_chars:\n",
        "        # Find the index of the first matched character in word1\n",
        "        first_match_index = word1.index(matched_chars[0])\n",
        "\n",
        "        # Extract the characters before and after the matched characters for word1\n",
        "        unmatched_chars1_before = word1[:first_match_index]\n",
        "        unmatched_chars1_after = word1[first_match_index + len(matched_chars):]\n",
        "\n",
        "        # Find the index of the first matched character in word2\n",
        "        first_match_index = word2.index(matched_chars[0])\n",
        "\n",
        "        # Extract the characters before and after the matched characters for word2\n",
        "        unmatched_chars2_before = word2[:first_match_index]\n",
        "        unmatched_chars2_after = word2[first_match_index + len(matched_chars):]\n",
        "    else:\n",
        "        unmatched_chars1_after = word1\n",
        "        unmatched_chars2_after = word2\n",
        "\n",
        "    return (\n",
        "        matched_chars,\n",
        "        unmatched_chars1_before,\n",
        "        unmatched_chars1_after,\n",
        "        unmatched_chars2_before,\n",
        "        unmatched_chars2_after\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWQ9NU1GtYLc"
      },
      "source": [
        "# ቃሉ ከርቢ ቃላት ጋር ያለው ርቀት"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMmNPW31smL3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compare_words(word1, word2):\n",
        "    matched, unmatched1_before, unmatched1_after, unmatched_chars2_before, unmatched_chars2_after = match_words(word1, word2)\n",
        "    # Step 3: Computing average distance between unmatched blocks\n",
        "    total_distance = 0.0\n",
        "    comparisons = 0\n",
        "    unmatched_dif2=0\n",
        "    unmatched_dif1=0\n",
        "    XX=0\n",
        "    if unmatched1_after or unmatched_chars2_after:\n",
        "        min_length2 = min(len(unmatched1_after), len(unmatched_chars2_after))\n",
        "        max_length2 = max(len(unmatched1_after), len(unmatched_chars2_after))\n",
        "        unmatched_dif2 = max_length2 - min_length2\n",
        "        for i in range(min_length2):\n",
        "          for j in range(min_length2):\n",
        "                char1 = unmatched1_after[i]\n",
        "                char2 = unmatched_chars2_after[j]\n",
        "\n",
        "                comparisons += 1\n",
        "                if char1 =='' :\n",
        "                  total_distance += 0.1\n",
        "\n",
        "                elif char2 =='':\n",
        "                  total_distance += 0.1\n",
        "\n",
        "                elif family(char1, char2) == 1 and order(char1, char2) == 1:\n",
        "                  total_distance += 1\n",
        "\n",
        "                elif family(char1, char2) == 1 and order(char1, char2) != 1:\n",
        "                  total_distance += 0.7\n",
        "\n",
        "                elif family(char1, char2) != 1 and order(char1, char2) == 1:\n",
        "                  total_distance += 0.5\n",
        "\n",
        "                elif family(char1, char2) != 1 and order(char1, char2) != 1:\n",
        "                    total_distance += 0.3\n",
        "\n",
        "    if unmatched1_before or unmatched_chars2_before:\n",
        "        min_length1 = min(len(unmatched1_before), len(unmatched_chars2_before))\n",
        "        max_length1 = max(len(unmatched1_before), len(unmatched_chars2_before))\n",
        "        unmatched_dif1 = max_length1 - min_length1\n",
        "        for i in range(min_length1):\n",
        "\n",
        "          for j in range(min_length1):\n",
        "                char1 = unmatched1_before[i]\n",
        "                char2 = unmatched_chars2_before[j]\n",
        "                comparisons += 1\n",
        "                if char1 =='' :\n",
        "                  total_distance += 0.1\n",
        "                elif char2 =='':\n",
        "                  total_distance += 0.1\n",
        "\n",
        "                elif family(char1, char2) == 1 and order(char1, char2) == 1:\n",
        "                  total_distance += 1\n",
        "                elif family(char1, char2) == 1 and order(char1, char2) != 1:\n",
        "                  total_distance += 0.7\n",
        "                elif family(char1, char2) != 1 and order(char1, char2) == 1:\n",
        "                  total_distance += 0.5\n",
        "                elif family(char1, char2) != 1 and order(char1, char2) != 1:\n",
        "                    total_distance += 0.3\n",
        "    total_distance += len(matched)\n",
        "    XX=(unmatched_dif1 + unmatched_dif2)\n",
        "    yy=(XX/10)\n",
        "    total_distance =yy+total_distance\n",
        "    total_distance = float(\"{:.1f}\".format(total_distance))\n",
        "    comparisons += unmatched_dif1 + unmatched_dif2+len(matched)\n",
        "    average_distance = total_distance / int(comparisons)\n",
        "    average_distance = \"\\033[91m\" + str(average_distance) + \"\\033[0m\"  # Set the value of word1 to red color\n",
        "    return matched, unmatched1_before, unmatched_chars2_before,unmatched1_after, unmatched_chars2_after, total_distance, comparisons, average_distance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNfRl4ictwZv"
      },
      "source": [
        "# prefix and suffix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OmaK4GDuwoU",
        "outputId": "5cda3c09-ca9a-4c49-a0f9-936c5600b7ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amharic_verb_prefixes: ['ይአ-', 'ኣ-', 'ኣ-ንኣ-', 'አ-', 'ኣ-ን-', 'ብአ-', 'ብኣ-ን-', 'ብኣ-', 'ብኣ-ንኣ-', 'ትኣ-', 'ትኣ-ንኣ-', 'ትአ-', 'ትኣ-ን-', 'ን-', 'ት-', 'ይ-', 'ትኤ-', 'ትኢ-']\n"
          ]
        }
      ],
      "source": [
        "import chardet\n",
        "\n",
        "file_path = '/content/drive/MyDrive/prefixes_repition_removed.txt'\n",
        "\n",
        "# Detect file encoding\n",
        "with open(file_path, 'rb') as file:\n",
        "    raw_data = file.read()\n",
        "    result = chardet.detect(raw_data)\n",
        "    encoding = result['encoding']\n",
        "\n",
        "# Read prefixes from text file\n",
        "with open(file_path, 'r', encoding=encoding) as file:\n",
        "    amharic_verb_prefixes = [line.strip() for line in file]\n",
        "\n",
        "print(\"amharic_verb_prefixes:\", amharic_verb_prefixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYNTr0MQuzCS",
        "outputId": "5ef88a5a-5e81-4566-d7b3-12f3856b957d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amharic_verb_suffixes: ['አ', 'አ-\\U0001e7eb-ም', 'አ-ንአ-ም', 'አ-ሕአ-ም', 'አ-ሕኡ-ም', 'አ-\\U0001e7e5-ም', 'አ-ሕ-ምኣ-ም', 'አ-አ-ም', 'አ-ም', 'አ-ኦ-ም', 'አ-ች-ም', 'አ-ምኣ-ም', 'አ-ን-ክአ-ም', 'አ-ን-ክኡ-ም', 'አ-ን-ኽ-ም', 'አ-ን-ክእ-ምኣ-ም', 'አ-\\U0001e7eb-ንአ-ም', 'አ-ሕ-ንኦ-ም', 'አ-\\U0001e7eb-ንኣ-ም', 'አ-ሕ-ንአ-ምኣ-ም', 'አ-ንኤ-ንኦ-ም', 'አ-ንኤ-ን-ክአ-ም', 'አ-ንኤ-ን-ክኡ-ም', 'አ-ንኤ-ን-ኽ-ም', 'አ-አ-ንኤ-ን-ክእ-ምኣ-ም', 'አ-ንኤ-ንአ-ም', 'አ-ንኤ-ንኣ-ም', 'አ-ንኤ-ንአ-ምኣ-ም', 'አ-ሕአ-ንኢ-ም', 'አ-ሕአ-ን-ድአ-ም', 'አ-ሕአ-ን-ሕኡ-ም', 'አ-ሕአ-ን-\\U0001e7e5-ም', 'አ-ሕአ-ን-ሕ-ምኣ-ም', 'አ-\\U0001e7ebአ-ንአ-ም', 'አ-ሕአ-ንኦ-ም', 'አ-ሕአ-ንኣ-ም', 'አ-ሕአ-ንአ-ምኣ-ም', 'አ-ሕኡ-ንኢ-ም', 'አ-ሕኡ-ን-ድአ-ም', 'አ-ሕኡ-ን-ክአ-ም', 'አ-ሕኡ-ን-ክኡ-ም', 'አ-ሕኡ-ን-ኽ-ም', 'አ-ሕኡ-ን-ክእ-ምኣ-ም', 'አ-ሕኡ-ንአ-ም', 'አ-ሕኡ-ንኦ-ም', 'አ-ሕኡ-ንኣ-ም', 'አ-ሕኡ-ንአ-ምኣ-ም', 'አ-ንኢ-ም', 'አ-ን-ድአ-ም', 'አ-ን-ሕአ-ም', 'አ-ን-ሕኡ-ም', 'አ-ን-\\U0001e7e5-ም', 'አ-ን-ሕ-ምኣ-ም', 'አ-ንኦ-ም', 'አ-ንኣ-ም', 'አ-ንአ-ምኣ-ም', 'አ-ኦ-ንኢ-ም', 'አ-ኦ-ን-ድአ-ም', 'አ-ኦ-ን-ክአ-ም', 'አ-ኦ-ን-ክኡ-ም', 'አ-ኦ-ን-ኽ-ም', 'አ-ኦ-ን-ክእ-ምኣ-ም', 'አ-ኦ-ንአ-ም', 'አ-ኦ-ንኦ-ም', 'አ-ኦ-ንኣ-ም', 'አ-ኦ-ንአ-ምኣ-ም', 'አ-ችአ-ንኢ-ም', 'አ-ችአ-ንአ-ድአ-ም', 'አ-ችአ-ንአ-ሕአ-ም', 'አ-ችአ-ንአ-ሕኡ-ም', 'አ-ችአ-ንአ-\\U0001e7e5-ም', 'አ-ችአ-ንአ-ሕ-ምኣ-ም', 'አ-ችአ-ንአ-ም', 'አ-ችአ-ንኦ-ም', 'አ-ችአ-ንኣ-ም', 'አ-ችአ-ንአ-ምኣ-ም', 'አ-ምኣ-ንኢ-ም', 'አ-ምኣ-ን-ድአ-ም', 'አ-ምኣ-ን-ሕአ-ም', 'አ-ምኣ-ን-ሕኡ-ም', 'አ-ምኣ-ን-\\U0001e7e5-ም', 'አ-ምኣ-ን-ሕ-ምኣ-ም', 'አ-ምኣ-ንአ-ም', 'አ-ምኣ-ንኦ-ም', 'አ-ምኣ-ንኣ-ም', 'አ-ምኣ-ንአ-ምኣ-ም', 'አ-ብ-ኢ-ም', 'አ-ብ-ን-ድአ-ም', 'አ-ብ-ሕአ-ም', 'አ-ብ-ሕኡ-ም', 'አ-ብ-\\U0001e7e5-ም', 'አ-ብ-አ-ሕ-ምኣ-ም', 'አ-ውአ-ም', 'አ-ብ-ኦ-ም', 'አ-ብ-ኣ-ም', 'አ-ብ-ሕ-ምኣ-ም', 'አ-ኦ-\\U0001e7f7ኢ-ም', 'አ-ኦ-\\U0001e7f7-ን-ድአ-ም', 'አ-ኦ-\\U0001e7f7አ-ም', 'አ-ኦ-ክኦ-ም', 'አ-ኦ-ኽ-ም', 'አ-ኦ-ክእ-ምኣ-ም', 'አ-ኦ-ክአ-ም', 'አ-ኦ-\\U0001e7f7ኣ-ም', 'አ-ኦ-ክአ-ምኣ-ም', 'አ-\\U0001e7eb', 'አ-ንአ', 'አ-ሕአ', 'አ-ሕኡ', 'አ-\\U0001e7e5', 'አ-ሕ-ምኣ', 'አ-ኦ', 'አ-ች', 'አ-ምኣ', 'አ-ን-ክአ', 'አ-ን-ክኡ', 'አ-ን-ኽ', 'አ-ን-ክእ-ምኣ', 'አ-\\U0001e7eb-ንአ', 'አ-ሕ-ንኦ', 'አ-\\U0001e7eb-ንኣ', 'አ-ሕ-ንአ-ምኣ', 'አ-ንኤ-ንኦ', 'አ-ንኤ-ን-ክአ', 'አ-ንኤ-ን-ክኡ', 'አ-ንኤ-ን-ኽ', 'አ--አ-ንኤ-ን-ክእ-ምኣ', 'አ-ንኤ-ንአ', 'አ-ንኤ-ንኣ', 'አ-ንኤ-ንአ-ምኣ', 'አ-ሕአ-ንኢ', 'አ-ሕአ-ን-ድአ', 'አ-ሕአ-ን-ሕኡ', 'አ-ሕአ-ን-\\U0001e7e5', 'አ-ሕአ-ን-ሕ-ምኣ', 'አ-\\U0001e7ebአ-ንአ', 'አ-ሕአ-ንኦ', 'አ-ሕአ-ንኣ', 'አ-ሕአ-ንአ-ምኣ', 'አ-ሕኡ-ንኢ', 'አ-ሕኡ-ን-ድአ', 'አ-ሕኡ-ን-ክአ', 'አ-ሕኡ-ን-ክኡ', 'አ-ሕኡ-ን-ኽ', 'አ-ሕኡ-ን-ክእ-ምኣ', 'አ-ሕኡ-ንአ', 'አ-ሕኡ-ንኦ', 'አ-ሕኡ-ንኣ', 'አ-ሕኡ-ንአ-ምኣ', 'አ-ንኢ', 'አ-ን-ድአ', 'አ-ን-ሕአ', 'አ-ን-ሕኡ', 'አ-ን-\\U0001e7e5', 'አ-ን-ሕ-ምኣ', 'አ-ንኦ', 'አ-ንኣ', 'አ-ንአ-ምኣ', 'አ-ኦ-ንኢ', 'አ-ኦ-ን-ድአ', 'አ-ኦ-ን-ክአ', 'አ-ኦ-ን-ክኡ', 'አ-ኦ-ን-ኽ', 'አ-ኦ-ን-ክእ-ምኣ', 'አ-ኦ-ንአ', 'አ-ኦ-ንኦ', 'አ-ኦ-ንኣ', 'አ-ኦ-ንአ-ምኣ', 'አ-ችአ-ንኢ', 'አ-ችአ-ንአ-ድአ', 'አ-ችአ-ንአ-ሕአ', 'አ-ችአ-ንአ-ሕኡ', 'አ-ችአ-ንአ-\\U0001e7e5', 'አ-ችአ-ንአ-ሕ-ምኣ', 'አ-ችአ-ንአ', 'አ-ችአ-ንኦ', 'አ-ችአ-ንኣ', 'አ-ችአ-ንአ-ምኣ', 'አ-ምኣ-ንኢ', 'አ-ምኣ-ን-ድአ', 'አ-ምኣ-ን-ሕአ', 'አ-ምኣ-ን-ሕኡ', 'አ-ምኣ-ን-\\U0001e7e5', 'አ-ምኣ-ን-ሕ-ምኣ', 'አ-ምኣ-ንአ', 'አ-ምኣ-ንኦ', 'አ-ምኣ-ንኣ', 'አ-ምኣ-ንአ-ምኣ', 'አ-ብ-ኢ', 'አ-ብ-ን-ድአ', 'አ-ብ-ሕአ', 'አ-ብ-ሕኡ', 'አ-ብ-\\U0001e7e5', 'አ-ብ-አ-ሕ-ምኣ', 'አ-ውአ', 'አ-ብ-ኦ', 'አ-ብ-ኣ', 'አ-ብ-ሕ-ምኣ', 'አ-ኦ-\\U0001e7f7ኢ', 'አ-ኦ-\\U0001e7f7-ን-ድአ', 'አ-ኦ-\\U0001e7f7አ', 'አ-ኦ-ክኦ', 'አ-ኦ-ኽ', 'አ-ኦ-ክእ-ምኣ', 'አ-ኦ-ክአ', 'አ-ኦ-\\U0001e7f7ኣ', 'አ-ኦ-ክአ-ምኣ', 'አ--አ-ንኤ-ን-ክእ-ምኣ-ም', 'አ-\\U0001e7eb-ም-ትኣ', 'አ-ንአ-ም-ትኣ', 'አ-ሕአ-ም-ትኣ', 'አ-ሕኡ-ም-ትኣ', 'አ-\\U0001e7e5-ም-ትኣ', 'አ-ሕ-ምኣ-ም-ትኣ', 'አ-ም-ትኣ', 'አ-ኦ-ም-ትኣ', 'አ-ች-ም-ትኣ', 'አ-ምኣ-ም-ትኣ', 'አ-ትኣ', 'አ-ን-ክአ-ም-ትኣ', 'አ-ን-ክኡ-ም-ትኣ', 'አ-ን-ኽ-ም-ትኣ', 'አ-ን-ክእ-ምኣ-ም-ትኣ', 'አ-ንኤ-ን-ክአ-ም-ትኣ', 'አ-ንኤ-ን-ክኡ-ም-ትኣ', 'አ-ንኤ-ን-ኽ-ም-ትኣ', 'አ--አ-ንኤ-ን-ክእ-ምኣ-ም-ትኣ', 'አ-ሕአ-ንኢ-ም-ትኣ', 'አ-ሕአ-ን-ድአ-ም-ትኣ', 'አ-ሕአ-ን-ሕኡ-ም-ትኣ', 'አ-ሕአ-ን-\\U0001e7e5-ም-ትኣ', 'አ-ሕአ-ን-ሕ-ምኣ-ም-ትኣ', 'አ-\\U0001e7ebአ-ንአ-ም-ትኣ', 'አ-ሕኡ-ንኢ-ም-ትኣ', 'አ-ሕኡ-ን-ድአ-ም-ትኣ', 'አ-ሕኡ-ን-ክአ-ም-ትኣ', 'አ-ሕኡ-ን-ክኡ-ም-ትኣ', 'አ-ሕኡ-ን-ኽ-ም-ትኣ', 'አ-ሕኡ-ን-ክእ-ምኣ-ም-ትኣ', 'አ-ንኢ-ም-ትኣ', 'አ-ን-ድአ-ም-ትኣ', 'አ-ን-ሕአ-ም-ትኣ', 'አ-ን-ሕኡ-ም-ትኣ', 'አ-ን-\\U0001e7e5-ም-ትኣ', 'አ-ን-ሕ-ምኣ-ም-ትኣ', 'አ-ኦ-ንኢ-ም-ትኣ', 'አ-ኦ-ን-ድአ-ም-ትኣ', 'አ-ኦ-ን-ክአ-ም-ትኣ', 'አ-ኦ-ን-ክኡ-ም-ትኣ', 'አ-ኦ-ን-ኽ-ም-ትኣ', 'አ-ኦ-ን-ክእ-ምኣ-ም-ትኣ', 'አ-ችአ-ንኢ-ም-ትኣ', 'አ-ችአ-ንአ-ድአ-ም-ትኣ', 'አ-ችአ-ንአ-ሕአ-ም-ትኣ', 'አ-ችአ-ንአ-ሕኡ-ም-ትኣ', 'አ-ችአ-ንአ-\\U0001e7e5-ም-ትኣ', 'አ-ችአ-ንአ-ሕ-ምኣ-ም-ትኣ', 'አ-ችአ-ንአ-ም-ትኣ', 'አ-ምኣ-ንኢ-ም-ትኣ', 'አ-ምኣ-ን-ድአ-ም-ትኣ', 'አ-ምኣ-ን-ሕአ-ም-ትኣ', 'አ-ምኣ-ን-ሕኡ-ም-ትኣ', 'አ-ምኣ-ን-\\U0001e7e5-ም-ትኣ', 'አ-ምኣ-ን-ሕ-ምኣ-ም-ትኣ', 'አ-ምኣ-ንአ-ም-ትኣ', 'አ-ብ-ኢ-ም-ትኣ', 'አ-ብ-ን-ድአ-ም-ትኣ', 'አ-ብ-ሕአ-ም-ትኣ', 'አ-ብ-ሕኡ-ም-ትኣ', 'አ-ብ-\\U0001e7e5-ም-ትኣ', 'አ-ብ-አ-ሕ-ምኣ-ም-ትኣ', 'አ-ውአ-ም-ትኣ', 'አ-ብ-ኦ-ም-ትኣ', 'አ-ብ-ኣ-ም-ትኣ', 'አ-ብ-ሕ-ምኣ-ም-ትኣ', 'አ-ኦ-\\U0001e7f7ኢ-ም-ትኣ', 'አ-ኦ-\\U0001e7f7-ን-ድአ-ም-ትኣ', 'አ-ኦ-\\U0001e7f7አ-ም-ትኣ', 'አ-ኦ-ክኦ-ም-ትኣ', 'አ-ኦ-ኽ-ም-ትኣ', 'አ-ኦ-ክእ-ምኣ-ም-ትኣ', 'አ-ኦ-ክአ-ም-ትኣ', 'አ-ኦ-\\U0001e7f7ኣ-ም-ትኣ', 'አ-ኦ-ክአ-ምኣ-ም-ትኣ', 'አ-\\U0001e7eb-ሕአ-ምኣ', 'አ-ንአ-ሕአ-ምኣ', 'አ-ሕአ-ሕአ-ምኣ', 'አ-ሕኡ-ሕአ-ምኣ', 'አ-\\U0001e7e5-ሕአ-ምኣ', 'አ-ሕ-ምኣ-ሕአ-ምኣ', 'አ-ሕአ-ምኣ', 'አ-ኦ-ሕአ-ምኣ', 'አ-ች-ሕአ-ምኣ', 'አ-ምኣ-ሕአ-ምኣ', 'አ-ኦ-ንኢ-ሕአ-ምኣ', 'አ-ኦ-ን-ድአ-ሕአ-ምኣ', 'አ-ኦ-ን-ክአ-ሕአ-ምኣ', 'አ-ኦ-ን-ክኡ-ሕአ-ምኣ', 'አ-ኦ-ን-ኽ-ሕአ-ምኣ', 'አ-ኦ-ን-ክእ-ምኣ-ሕአ-ምኣ', 'አ-ችአ-ንኢ-ሕአ-ምኣ', 'አ-ችአ-ንአ-ድአ-ሕአ-ምኣ', 'አ-ችአ-ንአ-ሕአ-ሕአ-ምኣ', 'አ-ችአ-ንአ-ሕኡ-ሕአ-ምኣ', 'አ-ችአ-ንአ-\\U0001e7e5-ሕአ-ምኣ', 'አ-ችአ-ንአ-ሕ-ምኣ-ሕአ-ምኣ', 'አ-ችአ-ንአ-ሕአ-ምኣ', 'አ-ምኣ-ንኢ-ሕአ-ምኣ', 'አ-ምኣ-ን-ድአ-ሕአ-ምኣ', 'አ-ምኣ-ን-ሕአ-ሕአ-ምኣ', 'አ-ምኣ-ን-ሕኡ-ሕአ-ምኣ', 'አ-ምኣ-ን-\\U0001e7e5-ሕአ-ምኣ', 'አ-ምኣ-ን-ሕ-ምኣ-ሕአ-ምኣ', 'አ-ምኣ-ንአ-ሕአ-ምኣ', 'አ-ብ-ኢ-ሕአ-ምኣ', 'አ-ብ-ን-ድአ-ሕአ-ምኣ', 'አ-ብ-ሕአ-ሕአ-ምኣ', 'አ-ብ-ሕኡ-ሕአ-ምኣ', 'አ-ብ-\\U0001e7e5-ሕአ-ምኣ', 'አ-ብ-አ-ሕ-ምኣ-ሕአ-ምኣ', 'አ-ውአ-ሕአ-ምኣ', 'አ-ብ-ኦ-ሕአ-ምኣ', 'አ-ብ-ኣ-ሕአ-ምኣ', 'አ-ብ-ሕ-ምኣ-ሕአ-ምኣ', 'አ-ኦ-\\U0001e7f7ኢ-ሕአ-ምኣ', 'አ-ኦ-\\U0001e7f7-ን-ድአ-ሕአ-ምኣ', 'አ-ኦ-\\U0001e7f7አ-ሕአ-ምኣ', 'አ-ኦ-ክኦ-ሕአ-ምኣ', 'አ-ኦ-ኽ-ሕአ-ምኣ', 'አ-ኦ-ክእ-ምኣ-ሕአ-ምኣ', 'አ-ኦ-ክአ-ሕአ-ምኣ', 'አ-ኦ-\\U0001e7f7ኣ-ሕአ-ምኣ', 'አ-ኦ-ክአ-ምኣ-ሕአ-ምኣ', 'አ-ንኢ-ሕአ-ምኣ', 'አ-ን-ድአ-ሕአ-ምኣ', 'አ-ን-ሕአ-ሕአ-ምኣ', 'አ-ን-ሕኡ-ሕአ-ምኣ', 'አ-ን-\\U0001e7e5-ሕአ-ምኣ', 'አ-ን-ሕ-ምኣ-ሕአ-ምኣ', 'ኦ']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "file_path = '/content/drive/MyDrive/suffixes removed repeation.txt'\n",
        "\n",
        "# Detect file encoding\n",
        "with open(file_path, 'rb') as file:\n",
        "    raw_data = file.read()\n",
        "    result = chardet.detect(raw_data)\n",
        "\n",
        "# Read prefixes from text file\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    amharic_verb_suffixes = [line.strip() for line in file]\n",
        "\n",
        "print(\"amharic_verb_suffixes:\", amharic_verb_suffixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM_mW_MMvHML",
        "outputId": "414bf542-1092-46ec-a68f-53180bb49875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amharic_noun_prefixe: ['ይአ-', 'ትአ-', 'ብአ-', 'አ-']\n"
          ]
        }
      ],
      "source": [
        "import chardet\n",
        "\n",
        "file_path1 = '/content/drive/MyDrive/Noun_prefixes  filttered.txt'\n",
        "\n",
        "# Detect file encoding\n",
        "with open(file_path1, 'rb') as file:\n",
        "    raw_data = file.read()\n",
        "    result = chardet.detect(raw_data)\n",
        "    encoding = result['encoding']\n",
        "\n",
        "# Read prefixes from text file\n",
        "with open(file_path1, encoding=encoding) as file:\n",
        "    amharic_noun_prefixes = [line.strip() for line in file]\n",
        "\n",
        "print(\"amharic_noun_prefixe:\", amharic_noun_prefixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2gZSKt4vXGk"
      },
      "outputs": [],
      "source": [
        "file_path2 = '/content/drive/MyDrive/nound_suffixes filtered .txt'\n",
        "# Detect file encoding\n",
        "with open(file_path2, 'rb') as file:\n",
        "    raw_data = file.read()\n",
        "    result = chardet.detect(raw_data)\n",
        "    encoding = result['encoding']\n",
        "\n",
        "# Read prefixes from text file\n",
        "with open(file_path2, 'r', encoding=encoding) as file:\n",
        "    amharic_noun_suffixes = [line.strip() for line in file]\n",
        "\n",
        "print(\"amharic_noun_suffixe:\", amharic_noun_suffixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9IoL6d-vckZ",
        "outputId": "82200fc0-1980-4255-ed17-b28b398be0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amharic_adj_prefixe: ['ትአ-', 'ብአ-', 'ይአ-', 'አ-']\n"
          ]
        }
      ],
      "source": [
        "import chardet\n",
        "\n",
        "file_path1 = '/content/drive/MyDrive/Adjective_prefixes filttered.txt'\n",
        "\n",
        "# Detect file encoding\n",
        "with open(file_path1, 'rb') as file:\n",
        "    raw_data = file.read()\n",
        "    result = chardet.detect(raw_data)\n",
        "    encoding = result['encoding']\n",
        "\n",
        "# Read prefixes from text file\n",
        "with open(file_path1, encoding=encoding) as file:\n",
        "    amharic_adj_prefixes = [line.strip() for line in file]\n",
        "\n",
        "print(\"amharic_adj_prefixe:\", amharic_adj_prefixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ3o4XGyvoRu"
      },
      "outputs": [],
      "source": [
        "file_path2 = '/content/drive/MyDrive/Adjective_suffixes  filttered.txt'\n",
        "# Detect file encoding\n",
        "with open(file_path2, 'rb') as file:\n",
        "    raw_data = file.read()\n",
        "    result = chardet.detect(raw_data)\n",
        "    encoding = result['encoding']\n",
        "\n",
        "# Read prefixes from text file\n",
        "with open(file_path2, 'r', encoding=encoding) as file:\n",
        "    amharic_adj_suffixes = [line.strip() for line in file]\n",
        "\n",
        "print(\"amharic_adj_suffixes:\", amharic_adj_suffixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwjDVWCQvoKl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4V7qgjEvp_K"
      },
      "outputs": [],
      "source": [
        "def load_dictionary():\n",
        "    with open('/content/drive/MyDrive/Noun_root.txt', 'r') as f:\n",
        "        noun_list.extend(f.read().splitlines())\n",
        "    with open('/content/drive/MyDrive/list of verbs_root.txt', 'r') as f:\n",
        "        verb_list.extend(f.read().splitlines())\n",
        "    with open('/content/drive/MyDrive/Adjective_root.txt', 'r') as f:\n",
        "        adjective_list.extend(f.read().splitlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHKIt_trvv9U"
      },
      "outputs": [],
      "source": [
        "# Check if a word is in the noun list\n",
        "def is_noun(word):\n",
        "    return word in noun_list\n",
        "\n",
        "# Check if a word is in the verb list\n",
        "def is_verb(word):\n",
        "    return word in verb_list\n",
        "\n",
        "# Check if a word is in the adjective list\n",
        "def is_adjective(word):\n",
        "    return word in adjective_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEFE75xdv7IV"
      },
      "outputs": [],
      "source": [
        "def read_amharic_prefixes_suffixes(file_path1, file_path2):\n",
        "    amharic_prefixes = []\n",
        "    amharic_suffixes = []\n",
        "\n",
        "    # Detect file encoding for prefixes\n",
        "    with open(file_path1, 'rb') as file:\n",
        "        raw_data = file.read()\n",
        "        result = chardet.detect(raw_data)\n",
        "        encoding = result['encoding']\n",
        "\n",
        "    # Read prefixes from text file\n",
        "    with open(file_path1, encoding=encoding) as file:\n",
        "        amharic_prefixes = [line.strip() for line in file]\n",
        "\n",
        "    # Detect file encoding for suffixes\n",
        "    with open(file_path2, 'rb') as file:\n",
        "      raw_data = file.read()\n",
        "      result = chardet.detect(raw_data)\n",
        "      # Read prefixes from text file\n",
        "    with open(file_path2, 'r', encoding='utf-8') as file:\n",
        "      amharic_suffixes = [line.strip() for line in file]\n",
        "    return amharic_prefixes, amharic_suffixes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVekgProisTS"
      },
      "outputs": [],
      "source": [
        "def remove_amharic_noun_affix(word):\n",
        "    for prefix in amharic_noun_prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            word = word[len(prefix):]\n",
        "            break\n",
        "    for suffix in amharic_noun_suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            word = word[:-len(suffix)]\n",
        "            break\n",
        "    return word#.rstrip(word[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzWq-4jMxbM7"
      },
      "outputs": [],
      "source": [
        "def remove_amharic_verb_affix(word):\n",
        "    for prefix in amharic_verb_prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            word = word[len(prefix):]\n",
        "            break\n",
        "    for suffix in amharic_verb_suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            word = word[:-len(suffix)]\n",
        "            break\n",
        "    return word#.rstrip(word[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE0GnCBLxgGj"
      },
      "outputs": [],
      "source": [
        "def remove_amharic_Adj_affix(word):\n",
        "    for prefix in amharic_adj_prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            word = word[len(prefix):]\n",
        "            break\n",
        "    for suffix in amharic_adj_suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            word = word[:-len(suffix)]\n",
        "            break\n",
        "    return word#.rstrip(word[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT7ROv4LPadp"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def find_closest_word(root_word, misspelled_word):\n",
        "    with open(root_word, \"r\", encoding=\"utf-8\") as file:\n",
        "        root_words = [line.strip() for line in file]\n",
        "\n",
        "    closest_word = difflib.get_close_matches(misspelled_word, root_words, n=1)\n",
        "    if closest_word:\n",
        "        return closest_word[0]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_amharic_paragraph(paragraph):\n",
        "    words = paragraph.split()\n",
        "    return words"
      ],
      "metadata": {
        "id": "RX1Tcc9GZTPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_amharic_word(word):\n",
        "    amharic_alphabet = am  # Add all Amharic characters to the list\n",
        "    for char in word:\n",
        "        if char not in amharic_alphabet:\n",
        "            return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "khvetm-EgBib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "\n",
        "# Download the Amharic tokenizer resources from NLTK\n",
        "nltk.download('punkt')\n",
        "\n",
        "def remove_last_character(line):\n",
        "    return line[:-1]\n",
        "\n",
        "def is_amharic_word(word):\n",
        "    amharic_alphabet = [...]  # Add all Amharic characters to the list\n",
        "    for char in word:\n",
        "        if char not in amharic_alphabet:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def tokenize_amharic_paragraph(paragraph):\n",
        "    words = nltk.word_tokenize(paragraph)\n",
        "    return words\n",
        "\n",
        "def remove_punctuation(word):\n",
        "    amharic_punctuation = \"።'\\\"፣፤፥.፦፧፨[]=-_{}\"\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation + amharic_punctuation)\n",
        "    word_without_punct = word.translate(translator)\n",
        "    return word_without_punct\n",
        "\n",
        "# Prompt the user to enter the Amharic paragraph\n",
        "amharic_paragraph = input(\"Enter the Amharic paragraph: \")\n",
        "\n",
        "# Tokenize the Amharic paragraph\n",
        "\n",
        "amharic_words = tokenize_amharic_paragraph(amharic_paragraph)\n",
        "print(amharic_words)\n",
        "# Remove punctuation from the Amharic words\n",
        "amharic_words_without_punct = [remove_punctuation(word) for word in amharic_words]\n",
        "print(amharic_words_without_punct)\n",
        "amharic_words_without_punct = [word for word in amharic_words_without_punct if word]  # Remove empty words\n",
        "print(amharic_words_without_punct)\n",
        "# amharic_words_without_punct is the list of Amharic words without punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGaAk18waKDJ",
        "outputId": "a866d711-96a8-4aa9-da2f-018c31081443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the Amharic paragraph: ቸነ\n",
            "['ቸነ']\n",
            "['ቸነ']\n",
            "['ቸነ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vAXQQx79fbrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5B3bRUZixAz",
        "outputId": "0f8f408f-b2da-49ce-8691-632ef3523c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amharic_paragrap['ቸነ','ቸነ𞟫ም','ቸነነም','ቸነሐም','ቸነሑም','ቸነ𞟥ም','ቸነሕማም','ቸነአም','ቸነም','ቸነኦም','ቸነችም','ቸነማም','ቸነንከም']\n",
            "The string 'ቸነ'noun'' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነ𞟫ም' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነነም' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነሐም'noun'' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነሑም'noun'' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነ𞟥ም'noun'' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነሕማም'noun'' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነአም' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነም'noun'' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነኦም' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነችም' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነማም'noun'' is \u001b[32mpresent\u001b[0m in the file.\n",
            "The string 'ቸነንከም' is \u001b[31mnot found\u001b[0m in the file.\n",
            "The spelling of 'ቸነንከም' \u001b[31mis incorrect. Did you mean: \u001b[32m['የቸነ', 'ኣቸነ', 'ኣናቸነ', 'አቸነ', 'ኣንቸነ', 'በቸነ', 'ባንቸነ', 'ባቸነ', 'ባናቸነ', 'ታቸነ']\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import difflib\n",
        "import os\n",
        "import glob\n",
        "from colorama import Fore, Style\n",
        "import re\n",
        "#word2 = ['ቸነቀም']#'ቸነ', 'ቸነጥም',\n",
        "word2 =['ቸነ','ቸነ𞟫ም','ቸነነም','ቸነሐም','ቸነሑም','ቸነ𞟥ም','ቸነሕማም','ቸነአም','ቸነም','ቸነኦም','ቸነችም','ቸነማም','ቸነንከም']\n",
        "count_present = 0\n",
        "count_not_present = 0\n",
        "distances_dict = {}\n",
        "noun_list=[]\n",
        "verb_list=[]\n",
        "adjective_list=[]\n",
        "amharic_paragraph = input(\"amharic_paragrap\")\n",
        "amharic_words = tokenize_amharic_paragraph(amharic_paragraph)\n",
        "amharic_words_without_punct = [remove_punctuation(word) for word in amharic_words]\n",
        "amharic_words_without_punct = [word for word in amharic_words_without_punct if word]  # Remove empty words\n",
        "word2=amharic_words_without_punct\n",
        "for w in word2:\n",
        "    newam = Erbata_TIGBERA(w, RIBI)\n",
        "    newam1 = remove_amharic_noun_affix(newam)\n",
        "    newam2 = remove_amharic_verb_affix(newam)\n",
        "    newam3 = remove_amharic_Adj_affix(newam)\n",
        "    amharic_word = w\n",
        "    search_string1 = newam1\n",
        "    search_string2 = newam2\n",
        "    search_string3 = newam3\n",
        "\n",
        "    RESET = '\\033[0m'\n",
        "    GREEN = '\\033[32m'\n",
        "    RED = '\\033[31m'\n",
        "\n",
        "    if check_string_in_file(file_path, search_string1):\n",
        "        catagory='noun'\n",
        "        search_string = search_string1\n",
        "        steam_form = so_called_steam_noun_word(newam1)\n",
        "        print(f\"The string '{remove_hyphen(amharic_word)}'{catagory}'' is {GREEN}present{RESET} in the file.\")\n",
        "        count_present += 1\n",
        "    elif check_string_in_file(file_path, search_string2):\n",
        "        catagory=''\n",
        "        search_string = search_string2\n",
        "        steam_form = so_called_steam_verb_word(newam2)\n",
        "        print(f\"The string '{remove_hyphen(amharic_word)}' is {GREEN}present{RESET} in the file.\")\n",
        "        count_present += 1\n",
        "    elif check_string_in_file(file_path, search_string3):\n",
        "        search_string = search_string1\n",
        "        steam_form = so_called_steam_adj_word(newam3)\n",
        "        print(f\"The string '{remove_hyphen(amharic_word)}' is {GREEN}present{RESET} in the file.\")\n",
        "        count_present += 1\n",
        "    else:\n",
        "        print(f\"The string '{remove_hyphen(amharic_word)}' is {RED}not found{RESET} in the file.\")\n",
        "        count_not_present += 1\n",
        "\n",
        "        closest1 = find_closest_word('/content/drive/MyDrive/all_root.txt', search_string)\n",
        "        closest = reverse_Erbata(closest1, RIBI)\n",
        "        load_dictionary()\n",
        "        if is_noun(closest1):\n",
        "          close_Aray = add_amharic_noun_affixes(closest1)\n",
        "        elif is_verb(closest1):\n",
        "          close_Aray = add_amharic_verb_affixes(closest1)\n",
        "        elif is_adjective(closest1):\n",
        "          close_Aray = add_amharic_Adj_affixes(closest1)\n",
        "        close_Aray_re = []\n",
        "        close_Aray_re_removed_phe = []\n",
        "        avaragedist = []\n",
        "\n",
        "        for word in close_Aray:\n",
        "            manipulated_word = reverse_Erbata(word, RIBI)\n",
        "            removed_phe = remove_hyphen(manipulated_word)\n",
        "            close_Aray_re.append(manipulated_word)\n",
        "            close_Aray_re_removed_phe.append(removed_phe)\n",
        "\n",
        "        if closest:\n",
        "            print(f\"The spelling of '{w}' {Fore.RED}is incorrect. Did you mean: {Fore.GREEN}{close_Aray_re_removed_phe[:10]}{Style.RESET_ALL}\")\n",
        "            word1 = w\n",
        "\n",
        "            for word in close_Aray_re_removed_phe:\n",
        "                matched, unmatched1_before, unmatched_chars2_before, unmatched1_after, unmatched_chars2_after, total_distance, comparisons, average_distance = compare_words(word1, word)\n",
        "\n",
        "                avaragedist.append(average_distance)\n",
        "                distances_dict[w] = average_distance\n",
        "                distances_dict[w] = float(re.sub(\"\\x1b\\[.*?m\", \"\", average_distance))\n",
        "        else:\n",
        "            print(f\"No close match found for '{search_string}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QgVY6RRA6W2",
        "outputId": "e654c230-da59-442e-d329-7594a3621e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distances Dictionary: {'ቸነንከም': 0.4}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "sorted_distances = sorted(avaragedist, key=lambda dist: float(re.sub(\"\\x1b\\[.*?m\", \"\", dist)))\n",
        "peak_value = float(re.sub(\"\\x1b\\[.*?m\", \"\", sorted_distances[-1]))\n",
        "\n",
        "\n",
        "print(\"Distances Dictionary:\", distances_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF6iAvRA7PPC",
        "outputId": "d17e6ab6-4f3c-4b30-fad9-447ac3576de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison between ቸነንከም and ቸነ\n",
            "unmatched1_before_match: ቸነ is: \n",
            "unmatched1_after_match: ቸነ is: ንከም\n",
            "Matched characters: ቸነ\n",
            "unmatched2_before_match: ቸነ is: \n",
            "unmatched2_After_match: ቸነ is: \n",
            "Total distance: 2.3\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.45999999999999996\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነ𞟫ም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: ም\n",
            "Total distance: 3.4\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.6799999999999999\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነነም\n",
            "unmatched1_before_match: ቸነነም is: \n",
            "unmatched1_after_match: ቸነነም is: ም\n",
            "Matched characters: ቸነነም\n",
            "unmatched2_before_match: ቸነነም is: \n",
            "unmatched2_After_match: ቸነነም is: \n",
            "Total distance: 4.1\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.82\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነሐም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: ም\n",
            "Total distance: 3.4\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.6799999999999999\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነሑም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: ም\n",
            "Total distance: 3.4\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.6799999999999999\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነ𞟥ም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: ም\n",
            "Total distance: 3.4\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.6799999999999999\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነሕማም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: ማም\n",
            "Total distance: 5.0\n",
            "Comparisons: 7\n",
            "Average distance: \u001b[91m0.7142857142857143\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነአም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: ም\n",
            "Total distance: 3.4\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.6799999999999999\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: \n",
            "Total distance: 3.2\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.64\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነኦም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: ም\n",
            "Total distance: 3.4\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.6799999999999999\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነችም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: ም\n",
            "Total distance: 3.4\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.6799999999999999\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነማም\n",
            "unmatched1_before_match: ቸነም is: \n",
            "unmatched1_after_match: ቸነም is: ከም\n",
            "Matched characters: ቸነም\n",
            "unmatched2_before_match: ቸነም is: \n",
            "unmatched2_After_match: ቸነም is: ም\n",
            "Total distance: 3.4\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m0.6799999999999999\u001b[0m\n",
            "\n",
            "Comparison between ቸነንከም and ቸነንከም\n",
            "unmatched1_before_match: ቸነንከም is: \n",
            "unmatched1_after_match: ቸነንከም is: \n",
            "Matched characters: ቸነንከም\n",
            "unmatched2_before_match: ቸነንከም is: \n",
            "unmatched2_After_match: ቸነንከም is: \n",
            "Total distance: 5.0\n",
            "Comparisons: 5\n",
            "Average distance: \u001b[91m1.0\u001b[0m\n",
            "\n",
            "Distances Dictionary: {'ቸነ': 0.45999999999999996, 'ቸነ\\U0001e7ebም': 0.6799999999999999, 'ቸነነም': 0.82, 'ቸነሐም': 0.6799999999999999, 'ቸነሑም': 0.6799999999999999, 'ቸነ\\U0001e7e5ም': 0.6799999999999999, 'ቸነሕማም': 0.7142857142857143, 'ቸነአም': 0.6799999999999999, 'ቸነም': 0.64, 'ቸነኦም': 0.6799999999999999, 'ቸነችም': 0.6799999999999999, 'ቸነማም': 0.6799999999999999, 'ቸነንከም': 1.0}\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "distances_dict = {}\n",
        "\n",
        "for w in word2:\n",
        "    matched, unmatched1_before, unmatched_chars2_before, unmatched1_after, unmatched_chars2_after, total_distance, comparisons, average_distance = compare_words(word1, w)\n",
        "    print(\"Comparison between\", word1, \"and\", w)\n",
        "    print(\"unmatched1_before_match:\", matched, \"is:\", unmatched1_before)\n",
        "    print(\"unmatched1_after_match:\", matched, \"is:\", unmatched1_after)\n",
        "    print(\"Matched characters:\", matched)\n",
        "    print(\"unmatched2_before_match:\", matched, \"is:\", unmatched_chars2_before)\n",
        "    print(\"unmatched2_After_match:\", matched, \"is:\", unmatched_chars2_after)\n",
        "    print(\"Total distance:\", total_distance)\n",
        "    print(\"Comparisons:\", comparisons)\n",
        "    print(\"Average distance:\", average_distance)\n",
        "    avaragedist.append(average_distance)\n",
        "    distances_dict[w] = average_distance\n",
        "    distances_dict[w] = float(re.sub(\"\\x1b\\[.*?m\", \"\", average_distance))\n",
        "    print()\n",
        "sorted_distances = sorted(avaragedist, key=lambda dist: float(re.sub(\"\\x1b\\[.*?m\", \"\", dist)))\n",
        "peak_value = float(re.sub(\"\\x1b\\[.*?m\", \"\", sorted_distances[-1]))\n",
        "\n",
        "print(\"Distances Dictionary:\", distances_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr1X12da7Vaj",
        "outputId": "ef5f670b-11e5-4bb4-9540-ab02ca5ae351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distances Dictionary: {'ቸነ': 0.45999999999999996, 'ቸነ\\U0001e7ebም': 0.6799999999999999, 'ቸነነም': 0.82, 'ቸነሐም': 0.6799999999999999, 'ቸነሑም': 0.6799999999999999, 'ቸነ\\U0001e7e5ም': 0.6799999999999999, 'ቸነሕማም': 0.7142857142857143, 'ቸነአም': 0.6799999999999999, 'ቸነም': 0.64, 'ቸነኦም': 0.6799999999999999, 'ቸነችም': 0.6799999999999999, 'ቸነማም': 0.6799999999999999, 'ቸነንከም': 1.0}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "sorted_distances = sorted(avaragedist, key=lambda dist: float(re.sub(\"\\x1b\\[.*?m\", \"\", dist)))\n",
        "peak_value = float(re.sub(\"\\x1b\\[.*?m\", \"\", sorted_distances[-1]))\n",
        "\n",
        "\n",
        "print(\"Distances Dictionary:\", distances_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B1Ou_i5XGibZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rena-I0opc-o",
        "tlegbBLS_49L",
        "KBi2opVBqJu9",
        "tbGztI1ipzeY",
        "GATlxdAmqXGE",
        "dt7lGInCqlmp",
        "Bdx5asePrdXz",
        "DPnH4Q0Rrtf-",
        "tnBcNS3xrzSv",
        "wDgSBKg1sQ4n",
        "U7ULOWofsjXI",
        "qf_j8vCgtJE9",
        "uWQ9NU1GtYLc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}